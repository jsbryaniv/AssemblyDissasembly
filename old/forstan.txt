
# Import standard modules
import os
import sys
import h5py
import copy
import time
import numpy as np
import numba as nb
import matplotlib.pyplot as plt
from scipy import stats
from types import SimpleNamespace

# Declare class
class StateInference:

    # Declare parameters
    PARAMETERS = {
        # Variables
        "s": None,
        "pi": None,
        "mu_flor": None,
        "mu_back": None,
        "gain": None,
        "P": None,
        # Priors
        "pi_conc": None,
        "mu_flor_shape": None,
        "mu_flor_scale": None,
        "mu_back_shape": None,
        "mu_back_scale": None,
        "gain_shape": None,
        "gain_scale": None,
        # Experiment
        "dt": 1,
        "num_states": 10,
        "num_frames": None,
        # Sampling
        "gain_proposal_shape": 10,
        "mu_flor_proposal_shape": 10,
        "mu_back_proposal_shape": 10,
    }

    # Define FFBS
    @staticmethod
    @nb.njit(cache=True)
    def FFBS(lhood, transition_matrix):

        # Get parameters
        num_states, num_data = lhood.shape
        pi0 = transition_matrix[-1, :]
        pis = transition_matrix[:-1, :]
        states = np.zeros(num_data, dtype=np.int32)

        # Forward filter
        forward = np.zeros((num_states, num_data))
        forward[:, 0] = lhood[:, 0] * pi0
        forward[:, 0] /= np.sum(forward[:, 0])
        for n in range(1, num_data):
            forward[:, n] = lhood[:, n] * (pis.T @ forward[:, n - 1])
            forward[:, n] /= np.sum(forward[:, n])

        # Backward sample
        s = np.searchsorted(np.cumsum(forward[:, -1]), np.random.rand())
        states[-1] = s
        for m in range(1, num_data):
            n = num_data - m - 1
            backward = forward[:, n] * pis[:, s]
            backward /= np.sum(backward)
            s = np.searchsorted(np.cumsum(backward), np.random.rand())
            states[n] = s

        return states

    @staticmethod
    def simulate_data(parameters=None, **kwargs):
        
        # Set up parameters
        default_parameters = {
            "dt": 1,
            "pi": None,
            "mu_flor": 100,
            "mu_back": 100,
            "gain": 100,
            "num_states": 10,
            "num_frames": 1000,
        }
        if parameters is None:
            parameters = {}
        parameters = copy.deepcopy(parameters)
        parameters = {**default_parameters, **parameters, **kwargs}

        # Set up variables
        variables = SimpleNamespace(**parameters)
        dt = variables.dt
        pi = variables.pi
        mu_flor = variables.mu_flor
        mu_back = variables.mu_back
        gain = variables.gain
        num_states = variables.num_states
        num_frames = variables.num_frames
        if pi is None:
            pi = np.zeros((num_states+1, num_states))
            for k in range(num_states):
                pi[k, k] = 100
                if k > 0:
                    pi[k, k-1] = 2
                if k < num_states - 1:
                    pi[k, k+1] = 1
                pi[k, :] /= np.sum(pi[k, :])
            pi[-1, 1] = 1
        
        # Simulate trajectory
        s = np.zeros(num_frames, dtype=int)
        s[0] = np.searchsorted(np.cumsum(pi[-1, :]), np.random.rand())
        for n in range(1, num_frames):
            s[n] = np.searchsorted(np.cumsum(pi[s[n-1], :]), np.random.rand())

        # Simulate data
        data = np.zeros(num_frames)
        for n in range(num_frames):
            scale = mu_flor*s[n] + mu_back
            data[n] = stats.gamma.rvs(a=gain, scale=scale)

        # Update parameters
        parameters["pi"] = pi
        parameters["s"] = s

        # Return
        return data, parameters


    @staticmethod
    def initialize_parameters(data, parameters=None, **kwargs):
        
        # Set up parameters
        if parameters is None:
            parameters = {}
        parameters = copy.deepcopy(parameters)
        parameters = {**StateInference.PARAMETERS, **parameters, **kwargs}

        # Set up variables
        variables = SimpleNamespace(**parameters)
        P = variables.P
        s = variables.s 
        pi = variables.pi
        pi_conc = variables.pi_conc
        mu_flor = variables.mu_flor
        mu_flor_shape = variables.mu_flor_shape
        mu_flor_scale = variables.mu_flor_scale
        mu_back = variables.mu_back
        mu_back_shape = variables.mu_back_shape
        mu_back_scale = variables.mu_back_scale
        gain = variables.gain
        gain_shape = variables.gain_shape
        gain_scale = variables.gain_scale
        dt = variables.dt
        num_states = variables.num_states
        num_frames = variables.num_frames
        mu_flor_proposal_shape = variables.mu_flor_proposal_shape
        mu_back_proposal_shape = variables.mu_back_proposal_shape

        # Initialize constants
        num_frames = data.shape[0]
        variables.num_frames = num_frames

        # Initialize gain
        if gain_shape is None:
            gain_shape = 2
        if gain_scale is None:
            gain_scale = 20
        if gain is None:
            gain = gain_shape * gain_scale
        variables.gain = gain
        variables.gain_shape = gain_shape
        variables.gain_scale = gain_scale

        # Initialize states
        s = np.zeros(num_frames, dtype=int)
        variables.s = s

        # Initialize transition probabilities
        if pi_conc is None:
            pi_conc = np.zeros((num_states+1, num_states))
            pi_conc[-1, :] = 1
            pi_conc[:-1, :] += (
                10 * np.eye(num_states)
                + np.eye(num_states, k=1)
                + np.eye(num_states, k=-1)
            )
            for k in range(num_states + 1):
                pi_conc[k, :] /= np.sum(pi_conc[k, :])
        if pi is None:
            pi = pi_conc.copy()
            for k in range(num_states + 1):
                pi[k, :] /= np.sum(pi[k, :])
        variables.pi = pi
        variables.pi_conc = pi_conc

        # Initialize background 
        if mu_back_shape is None:
            mu_back_shape = 2
        if (mu_back_scale is None) and (data is not None):
            mu_back_scale = np.mean(np.sort(data)[:int(num_frames/10)]) / gain / mu_back_shape
        if mu_back is None:
            mu_back = mu_back_shape * mu_back_scale
        variables.mu_back = mu_back
        variables.mu_back_shape = mu_back_shape
        variables.mu_back_scale = mu_back_scale

        # Initialize fluorophore brightness
        if mu_flor_shape is None:
            mu_flor_shape = 2
        if (mu_flor_scale is None) and (data is not None):
            mu_flor_scale = (np.mean(np.sort(data)[-int(num_frames/10):]) / gain - mu_back) / mu_flor_shape
        if mu_flor is None:
            mu_flor = mu_flor_shape * mu_flor_scale
        variables.mu_flor = mu_flor
        variables.mu_flor_shape = mu_flor_shape
        variables.mu_flor_scale = mu_flor_scale

        # Initialze probability
        P = -np.inf
        variables.P = P
            
        # Return variables
        return variables

    @staticmethod
    def sample_states(data, variables):
        
        # Extract variables
        s = variables.s
        pi = variables.pi
        mu_flor = variables.mu_flor
        mu_back = variables.mu_back
        dt = variables.dt
        gain = variables.gain
        num_states = variables.num_states
        num_frames = variables.num_frames

        # Set up log likelihood matrix
        lhood = np.zeros((num_states, num_frames))
        for k in range(num_states):
            mu = k*mu_flor + mu_back
            lhood[k, :] = stats.gamma.logpdf(data, a=gain, scale=mu)

        # Softmax for numerical stability
        lhood = np.exp(lhood - np.max(lhood, axis=0))

        # Sample states using FFBS
        s[:] = StateInference.FFBS(lhood, pi)

        # Update variables
        variables.s = s

        # Return variables
        return variables

    @staticmethod
    def sample_transitions(data, variables):
        
        # Extract variables
        s = variables.s
        pi = variables.pi
        pi_conc = variables.pi_conc
        num_states = variables.num_states
        num_frames = variables.num_frames

        # Get counts
        counts = np.zeros((num_states+1, num_states))
        s_old = -1
        for n in range(num_frames):
            s_new = s[n]
            counts[s_old, s_new] += 1
            s_old = s_new

        # Sample transition probabilities
        for k in range(num_states + 1):
            ids = pi_conc[k, :] > 0
            pi[k, ids] = stats.dirichlet.rvs(counts[k, ids] + pi_conc[k, ids])
        pi += 1e-100

        # Return variables
        return variables

    @staticmethod
    def sample_brightness(data, variables):

        # Extract variables
        s = variables.s
        mu_flor = variables.mu_flor
        mu_flor_shape = variables.mu_flor_shape
        mu_flor_scale = variables.mu_flor_scale
        mu_back = variables.mu_back
        mu_back_shape = variables.mu_back_shape
        mu_back_scale = variables.mu_back_scale
        dt = variables.dt
        gain = variables.gain
        num_states = variables.num_states
        num_frames = variables.num_frames
        mu_flor_proposal_shape = variables.mu_flor_proposal_shape
        mu_back_proposal_shape = variables.mu_back_proposal_shape

        # Define conditional probability
        def prob(mu_flor_, mu_back_):
            # Calculate prior
            P = (
                stats.gamma.logpdf(mu_flor_, a=mu_flor_shape, scale=mu_flor_scale)
                + stats.gamma.logpdf(mu_back_, a=mu_back_shape, scale=mu_back_scale)
            )
            # Calculate likelihood
            for k in range(num_states):
                ids = np.where(s == k)[0]
                mu = k * mu_flor_ + mu_back_
                P += (
                    np.sum(stats.gamma.logpdf(data[ids], a=gain, scale=mu))
                )
            return P

        # Sample brightnesses
        for _ in range(10):

            # Sample background
            a = mu_back_proposal_shape
            mu_back_old = copy.deepcopy(mu_back)
            mu_back_new = stats.gamma.rvs(a=a, scale=mu_back_old/a)
            P_old = prob(mu_flor, mu_back_old)
            P_new = prob(mu_flor, mu_back_new)
            acc_prob = (
                P_new - P_old
                + stats.gamma.logpdf(mu_back_old, a=a, scale=mu_back_new/a)
                - stats.gamma.logpdf(mu_back_new, a=a, scale=mu_back_old/a)
            )
            if acc_prob > np.log(np.random.rand()):
                mu_back = mu_back_new
            
            # Sample fluorophore brightness
            a = mu_flor_proposal_shape
            mu_flor_old = copy.deepcopy(mu_flor)
            mu_flor_new = stats.gamma.rvs(a=a, scale=mu_flor_old/a)
            P_old = prob(mu_flor_old, mu_back)
            P_new = prob(mu_flor_new, mu_back)
            acc_prob = (
                P_new - P_old
                + stats.gamma.logpdf(mu_flor_old, a=a, scale=mu_flor_new/a)
                - stats.gamma.logpdf(mu_flor_new, a=a, scale=mu_flor_old/a)
            )
            if acc_prob > np.log(np.random.rand()):
                mu_flor = mu_flor_new

        # Update variables
        variables.mu_flor = mu_flor
        variables.mu_back = mu_back

        # Return variables
        return variables

    @staticmethod
    def sample_gain(data, variables):

        # Extract variables
        s = variables.s
        pi = variables.pi
        mu_flor = variables.mu_flor
        mu_back = variables.mu_back
        dt = variables.dt
        gain = variables.gain
        num_states = variables.num_states
        num_frames = variables.num_frames
        gain_proposal_shape = variables.gain_proposal_shape

        # Define conditional probability
        trace = np.zeros_like(data)
        for k in range(num_states):
            ids = np.where(s == k)[0]
            trace[ids] = k * mu_flor + mu_back
        def prob(gain_):
            P = np.sum(stats.gamma.logpdf(data, a=gain_, scale=trace))
            return P
        
        # Sample gain
        a = gain_proposal_shape
        for _ in range(10):
            gain_old = copy.deepcopy(gain)
            gain_new = stats.gamma.rvs(a=a, scale=gain_old/a)
            P_old = prob(gain_old)
            P_new = prob(gain_new)
            acc_prob = (
                P_new - P_old
                + stats.gamma.logpdf(gain_old, a=a, scale=gain_new/a)
                - stats.gamma.logpdf(gain_new, a=a, scale=gain_old/a)
            )
            if acc_prob > np.log(np.random.rand()):
                gain = gain_new
        
        # Update variables
        variables.gain = gain

        # Return variables
        return variables
    
    @staticmethod
    def sample_states_and_brightness(data, variables):

        # Sample new brightnesses
        variables_old = variables
        variables_new = copy.deepcopy(variables)
        mu_flor_old = variables_old.mu_flor
        mu_flor_new = stats.expon.rvs(scale=mu_flor_old)
        variables_new.mu_flor = mu_flor_new
        variables_new = StateInference.sample_states(data, variables_new)

        # Calculate acceptance probability
        P_old = StateInference.calculate_posterior(data, variables_old)
        P_new = StateInference.calculate_posterior(data, variables_new)
        acc_prob = (
            P_new - P_old
            + stats.expon.logpdf(mu_flor_old, scale=mu_flor_new)
            - stats.expon.logpdf(mu_flor_new, scale=mu_flor_old)
        )
        if acc_prob > np.log(np.random.rand()):
            variables = variables_new
        
        # Return variables
        return variables
    
    @staticmethod
    def sample_states_and_background(data, variables):

        # Sample new brightnesses
        variables_old = variables
        variables_new = copy.deepcopy(variables)
        mu_back_old = variables_old.mu_flor
        mu_back_new = stats.expon.rvs(scale=mu_back_old)
        variables_new.mu_flor = mu_back_new
        variables_new = StateInference.sample_states(data, variables_new)

        # Calculate acceptance probability
        P_old = StateInference.calculate_posterior(data, variables_old)
        P_new = StateInference.calculate_posterior(data, variables_new)
        acc_prob = (
            P_new - P_old
            + stats.expon.logpdf(mu_back_old, scale=mu_back_new)
            - stats.expon.logpdf(mu_back_new, scale=mu_back_old)
        )
        if acc_prob > np.log(np.random.rand()):
            variables = variables_new
        
        # Return variables
        return variables
    
    @staticmethod
    def calculate_posterior(data, variables, **kwargs):

        # Set up variables
        if len(kwargs) > 0:
            variables = copy.copy(variables)
            for key, value in kwargs.items():
                setattr(variables, key, value)
        
        # Get variables
        s = variables.s
        pi = variables.pi
        pi_conc = variables.pi_conc
        mu_flor = variables.mu_flor
        mu_flor_shape = variables.mu_flor_shape
        mu_flor_scale = variables.mu_flor_scale
        mu_back = variables.mu_back
        mu_back_shape = variables.mu_back_shape
        mu_back_scale = variables.mu_back_scale
        gain = variables.gain
        gain_shape = variables.gain_shape
        gain_scale = variables.gain_scale
        dt = variables.dt
        num_states = variables.num_states
        num_frames = variables.num_frames

        # Calculate prior
        prior = (
            stats.gamma.logpdf(mu_flor, a=mu_flor_shape, scale=mu_flor_scale)
            + stats.gamma.logpdf(mu_back, a=mu_back_shape, scale=mu_back_scale)
            + stats.gamma.logpdf(gain, a=gain_shape, scale=gain_scale)
        )
        for k in range(num_states + 1):
            ids = pi_conc[k, :] > 0
            prior += stats.dirichlet.logpdf(pi[k, ids], pi_conc[k, ids])

        # Calculate likelihood
        likelihood = 0
        for k in range(num_states):
            ids = np.where(s == k)[0]
            mu = k * mu_flor + mu_back
            likelihood += (
                np.sum(stats.gamma.logpdf(data[ids], a=gain, scale=mu))
            )

        # Calculate dynamics
        dynamics = 0
        s_old = -1
        for n in range(num_frames):
            s_new = s[n]
            dynamics += np.log(pi[s_old, s_new])
            s_old = s_new

        # Calculate posterior
        P = prior + likelihood + dynamics

        return P

    @staticmethod
    def plot_data(data, variables=None):

        # Set up figure
        fig = plt.gcf()
        fig.clf()
        plt.ion()
        plt.show()
        ax = fig.add_subplot(111)

        # Plot data
        ax.plot(data, "r", label="Data")

        # Plot variables
        if variables is not None:
            # Get variables
            s = variables.s
            mu_flor = variables.mu_flor
            mu_back = variables.mu_back
            gain = variables.gain
            num_states = variables.num_states
            # Calculate trace
            trace = np.zeros_like(data)
            for k in range(num_states):
                ids = np.where(s == k)[0]
                trace[ids] = gain*(k * mu_flor + mu_back)
            # Plot trace
            ax.plot(trace, "b", label=f"Trace\nMax={np.max(s)}")

        # Set up plot
        ax.set_ylabel("Intensity (ADU)")
        ax.set_xlabel("Time (Frame #)")
        ax.legend()
        plt.tight_layout()
        plt.pause(.1)

        # Finish
        return

    @staticmethod
    def analyze_data(data, parameters=None, num_iterations=100, plot=False, verbose=False, **kwargs):

        # Initialize variables
        variables = StateInference.initialize_parameters(data, parameters, **kwargs)
        MAPvariables = copy.deepcopy(variables)

        # Gibbs sampling
        for iteration in range(num_iterations):
            if verbose:
                print(f"Iteration {iteration+1}/{num_iterations}", end='')
            t = time.time()
                
            # Sample states
            variables = StateInference.sample_gain(data, variables)
            variables = StateInference.sample_brightness(data, variables)
            variables = StateInference.sample_transitions(data, variables)
            variables = StateInference.sample_states(data, variables)
            if np.random.rand() < .25:
                variables = StateInference.sample_states_and_brightness(data, variables)

            # Update MAP
            variables.P = StateInference.calculate_posterior(data, variables)
            if variables.P >= MAPvariables.P:
                MAPvariables = copy.deepcopy(variables)

            # Plot
            if plot:
                StateInference.plot_data(data, variables)
                plt.pause(.1)

            # Print
            if verbose:
                print(f" ({time.time()-t:.2f} s) P = {variables.P:.2f}")

        # Return MAP variables
        return MAPvariables



data, parameters = StateInference.simulate_data()
states = StateInference.analyze_data(data).s
transitiontimes = np.where(states[:-1] != states[1:])[0]

plt.plot(data)
plt.plot(states*5000)
plt.vlines(transitiontimes, np.min(data), np.max(data), color="r", linestyle="--")

print("done")
